Is an automatic or manual transmission better for MPG ?
========================================================
  
  ## Summary
  The essense of this study was exploring the relationship bewteen a set of variable in tht mtcars datase taken from and miles per gallon (MPG) parameter as an outcome. Paricularly, the bigest attention has beenn taken in annsweringn the followingn two questions:

* Is an automatic or manual transmission better for miles/(US) gallon (MPG) ?
* Quantifying how different is the MPG between automatic and manual transmissions?

The analysis required for ansnweringn these two questions contained of three parts:
* setting the statistical frame of these problems
* using the *backward-elimination* strategy to choose the best fit model
* comparing the final model to different diagnostic tools and visualizing the data and residuals.

## Statistical Frame
Our dataset `mtcars` contains **`r nrow(mtcars)`** observations of the following **`r ncol(mtcars)`** variables.
* [, 1]  `mpg`   Miles/(US) gallon
* [, 2]	 `cyl`	 Number of cylinders
* [, 3]	 `disp`	 Displacement (cu.in.)
* [, 4]	 `hp`	 Gross horsepower
* [, 5]	 `drat`	 Rear axle ratio
* [, 6]	 `wt`	 Weight (lb/1000)
* [, 7]	 `qsec`	 1/4 mile time
* [, 8]	 `vs`	 V/S
* [, 9]	 `am`	 Transmission (0 = automatic, 1 = manual)
* [,10]	 `gear`	 Number of forward gears
* [,11]	 `carb`	 Number of carburetors

We can frame this into a **two-sided statistical hypothesis test** :
  
  $H_O$ : $\beta_1 = 0$. The true linear model has the slope zero for `am`, which means that the transmission mode does not relate to the number of miles per gallon of the car.

$H_A$ : $\beta_1 \neq 0$. The true linear model has the slope different from zero for `am`. If $\beta_1$ is positive, it means manual transmission can have $\beta_1$ **more** mpg in comparison with automatic mode. If $\beta_1$ is negative, the manual transmission will have $\beta_1$ **less** mpg than automatic mode.


## Model Selection

Let's first do a multivarible regression as following
```{r}
summary(lm(mpg ~ ., data = mtcars))$coefficients
```
We will then use the **backward-elimination** strategy to eliminate the unrelated variables one-at-a-time. It means, we first fit a model which includes all the potential variables as above, now we drop the variable `cyl` as it has the largest p-value, then we refit the model. All the details of the model selection are attached in Appendix A.

In the new model, there is no strong evidence that the coefficient of the variable `vs` is different from zero even though its p-value decreased a little bit, so we again eliminate the variable with the largest p-value `vs` and refit the model

With the same strategy, we can now eliminate the variable largest p-value as `carb`, `gear`, `drat` `disp`, `hp` and the intercept in order and refit the model. The final model is
```{r}
dat <- mtcars[, c("mpg", "wt", "qsec", "am")]
fit <- lm(mpg ~ . - 1, data = dat)
summary(fit)$coefficients
```
It includes only `wt`, `qsec` and `am` in predicting the miles per gallon of a vehicle
$$
\hat y = `r fit$coef["wt"]` x_{wt} + `r fit$coef["qsec"]` x_{qsec} + `r fit$coef["am"]` x_{am}
$$
Where $x_{wt}$, $x_{qsec}$ and $x_{am}$ represent the variables `wt`, `qsec` and `am`.

As the two-sided p-value for the coefficient of `am` is `r summary(fit)$coefficients["am", 4]`, much smaller than 0.05, we have enough evidence to reject the hypothesis $H_0$.

## Exploratory Analysis

Before we draw a conclusion of the final model obtained, we can check the relation between `mpg` and the three variables in our final model again.
```{r fig.width = 6, fig.height = 6}
pairs(dat, panel = panel.smooth, main = "mtcars data")
```
As shown in the figure above, the linear relationship bewteen `mpg` and the three variables is quite strong. We can also plot the residual and other variations of the final fit
```{r fig.width = 8, fig.height = 8}
par(mfrow = c(2, 2))
plot(fit)
```
We note that the residuals show no obvious pattern, so it is reasonable to try to fit a linear model to the data.

## Conclusion
Now with all the previous analysis, we can conclude that our linear model is a resonable fit. As
```{r}
sumCoef <- summary(fit)$coefficients
intv <- sumCoef["am", 1] + c(-1, 1) * qt(0.975, df = fit$df)*sumCoef["am", 2]
intv
```
With 95% confidence, we estimate that a the change from automatic to manual transmission results in a `r round(intv[1],2)` to `r round(intv[2],2)` increase in miles per gallon for the cars. In conclusion, the manual transmission is better than automatic transmission for mpg.

-----------
## Appendix A. Model Selection Details
```{r}
dat <- mtcars
dat <- dat[, names(dat) != "cyl"]
summary(lm(mpg ~ ., data = dat))$coefficients
dat <- dat[, names(dat) != "vs"]
summary(lm(mpg ~ ., data = dat))$coefficients
dat <- dat[, names(dat) != "carb"]
summary(lm(mpg ~ ., data = dat))$coefficients
dat <- dat[, names(dat) != "gear"]
summary(lm(mpg ~ ., data = dat))$coefficients
dat <- dat[, names(dat) != "drat"]
summary(lm(mpg ~ ., data = dat))$coefficients
dat <- dat[, names(dat) != "disp"]
summary(lm(mpg ~ ., data = dat))$coefficients 
dat <- dat[, names(dat) != "hp"]
summary(lm(mpg ~ ., data = dat))$coefficients 
summary(lm(mpg ~ . -1, data = dat))$coefficients 
```
As the p-value of all the remaining predictors are smaller than $0.05$, we can stop.
